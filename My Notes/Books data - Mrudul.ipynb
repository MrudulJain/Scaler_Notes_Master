{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "929e6812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5a74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_extractor(url):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.content)\n",
    "    \n",
    "    cols = ['product_page_url', 'title', 'universal_product_code', 'price_including_tax', \n",
    "            'price_excluding_tax', 'number_available', 'category', 'review_rating']\n",
    "    df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    booklib = soup.findAll('li', class_ = \"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "    for book in booklib:\n",
    "        '''\n",
    "        SOME DATA SUCH AS UPC, PRICE (TAX), NUMBER AVAILABLE IS ONLY AVAILABLE IN THE INDIVIDUAL BOOK URLS. \n",
    "        THEREFORE, WE WILL FIRST GET THE DATA THAT IS AVAILABLE ON THE TRAVEL BOOKS URL DIRECTLY\n",
    "        SEE BELOW CELLS FOR STEP-BY-STEP GUIDE\n",
    "        '''\n",
    "        \n",
    "        # 1. Product Page URL\n",
    "        short_url = book.h3.a[\"href\"]\n",
    "        suffix = \"http://books.toscrape.com/catalogue\"\n",
    "        short_url = short_url.split(\"/\")[3:]\n",
    "        product_page_url = suffix + \"/\" + short_url[0] + \"/\" + short_url[1]\n",
    "        \n",
    "        # 2. Book Title\n",
    "        title = book.h3.a[\"title\"]\n",
    "        \n",
    "        # 3. Category\n",
    "        category = \"Travel\"\n",
    "        \n",
    "        # 4. Review Rating\n",
    "        rating = book.p[\"class\"][1]\n",
    "        \n",
    "        # To get UPC, Price, Avaialability we need to get individual URLs for each book and get info \n",
    "        # from \"Product Information\" table\n",
    "        \n",
    "        book_req = requests.get(product_page_url)\n",
    "        booksoup = BeautifulSoup(book_req.content)\n",
    "        bookinfo = booksoup.find('table', class_ = \"table table-striped\") #Only need one-table to we will use \"find\"\n",
    "        rows = bookinfo.findAll(\"tr\")\n",
    "        \n",
    "        # 5. UPC, Price, Availability\n",
    "        UPC = rows[0].find(\"td\").text\n",
    "        price_exc_tax = rows[2].find(\"td\").text\n",
    "        price_inc_tax = rows[3].find(\"td\").text\n",
    "        stock = rows[5].find(\"td\").text\n",
    "        \n",
    "        vals = [product_page_url, title, UPC, price_exc_tax, price_inc_tax, stock, category, rating]\n",
    "        df = pd.concat([df, pd.DataFrame([vals], columns=df.columns)], axis=0, ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32e4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://books.toscrape.com/catalogue/category/books/travel_2/index.html\"\n",
    "df = scaler_extractor(url)\n",
    "df.to_csv(\"WebScrapping.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd25466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
