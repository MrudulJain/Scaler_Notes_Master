{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4846719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "#import gradio as gr\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f42170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLanguageModel:\n",
    "    def __init__(self, n_params=5):\n",
    "        random.seed(42)\n",
    "        self.n_params = n_params\n",
    "        self.state = [{} for _ in range(n_params)]\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.num_train_tokens = 0\n",
    "        print(f\"Model initialized with n_params={n_params}\")\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Tokenize text into words and punctuation\"\"\"\n",
    "        return re.findall(r\"\\b[a-zA-Z0-9]+\\b|[.]\", text.lower())\n",
    "    \n",
    "    def get_data(self):\n",
    "        with open('data/weather_data.txt', 'r', encoding='utf-8') as file:\n",
    "            corpus = file.read()\n",
    "        tokens = self.tokenize(corpus)\n",
    "        split_index = int(len(tokens) * 0.90)\n",
    "        train_corpus = tokens[:split_index]\n",
    "        test_corpus = tokens[split_index:]\n",
    "        print(f\"Data loaded: {len(tokens)} total tokens\")\n",
    "        print(f\"Training: {len(train_corpus)} tokens\")\n",
    "        print(f\"Testing: {len(test_corpus)} tokens\")\n",
    "        return train_corpus, test_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f55c8e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with n_params=3\n",
      "n_params: 3\n",
      "state: [{}, {}, {}]\n",
      "train_data: None\n",
      "test_data: None\n",
      "num_train_tokens: 0\n",
      "====================================================================================================\n",
      "Data loaded: 2445 total tokens\n",
      "Training: 2200 tokens\n",
      "Testing: 245 tokens\n",
      "Training data sample: ['daily', 'weather', 'reports', 'for', 'major', 'indian', 'cities', 'mumbai', 'weather', 'report']\n",
      "Test data sample: ['conditions', 'in', 'delhi', 'to', 'continue']\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "model = BasicLanguageModel(n_params=3)\n",
    "\n",
    "for attr_name, attr_value in vars(model).items():\n",
    "    print(f\"{attr_name}: {attr_value}\")\n",
    "    \n",
    "print(\"=\"*100)\n",
    "    \n",
    "# Load data\n",
    "model.train_data, model.test_data = model.get_data()\n",
    "model.num_train_tokens = len(model.train_data)\n",
    "\n",
    "print(f\"Training data sample: {model.train_data[:10]}\")\n",
    "print(f\"Test data sample: {model.test_data[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0917cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    tokens = model.train_data\n",
    "    \n",
    "    for ind in range(1, model.n_params + 1): # ind == 1 to 4 (ngram = 3)\n",
    "        counts = model.state[ind - 1]\n",
    "        ngram_count = 0\n",
    "        \n",
    "        for i in range(len(tokens) - ind + 1):\n",
    "            context = tuple(tokens[i:i + ind - 1])\n",
    "            next_token = tokens[i + ind - 1]\n",
    "            \n",
    "            if context not in counts:\n",
    "                counts[context] = defaultdict(int)\n",
    "            counts[context][next_token] += 1\n",
    "            ngram_count += 1\n",
    "        \n",
    "        print(f\"Trained {ind}-gram model: {ngram_count} n-grams processed\")\n",
    "        print(f\"Unique contexts: {len(counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e983a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 1-gram model: 2200 n-grams processed\n",
      "Unique contexts: 1\n",
      "Trained 2-gram model: 2199 n-grams processed\n",
      "Unique contexts: 150\n",
      "Trained 3-gram model: 2198 n-grams processed\n",
      "Unique contexts: 317\n"
     ]
    }
   ],
   "source": [
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fb197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== N-gram Model Statistics ===\n",
      "\n",
      "1-gram model:\n",
      "  Total contexts: 1\n",
      "  Sample contexts and their next tokens:\n",
      "    () → {'daily': 1, 'weather': 69, 'reports': 1, 'for': 43, 'major': 1, 'indian': 1, 'cities': 1, 'mumbai': 48, 'report': 42, 'monday': 6, 'the': 133, 'temperature': 43, 'in': 132, 'today': 86, 'is': 84, '32': 5, 'degrees': 43, 'celsius': 43, '.': 217, 'will': 43, 'experience': 42, 'high': 19, 'humidity': 21, 'expect': 44, 'light': 6, 'rainfall': 18, 'during': 16, 'evening': 6, 'hours': 4, 'wind': 42, 'speed': 42, '15': 4, 'kilometers': 42, 'per': 42, 'hour': 42, 'residents': 44, 'of': 43, 'should': 44, 'carry': 12, 'umbrellas': 12, 'delhi': 45, '38': 1, 'dry': 9, 'clear': 12, 'skies': 25, 'throughout': 25, 'day': 23, '10': 3, 'stay': 14, 'hydrated': 11, 'chennai': 42, '35': 3, 'partly': 12, 'cloudy': 12, 'afternoon': 9, '12': 5, 'use': 7, 'sunscreen': 7, 'kolkata': 42, '33': 5, 'moderate': 9, '14': 4, 'bengaluru': 42, '28': 3, 'pleasant': 11, '18': 3, 'enjoy': 6, 'hyderabad': 42, '8': 2, 'tuesday': 6, '31': 4, '17': 1, '39': 1, 'very': 1, 'hot': 4, 'indoors': 3, 'peak': 1, '34': 4, 'heavy': 3, '16': 4, 'avoid': 6, 'unnecessary': 2, 'travel': 3, '27': 3, '20': 3, '9': 2, 'wednesday': 6, '36': 3, '30': 5, '26': 2, '22': 2, 'humid': 2, '11': 3, 'thursday': 6, 'continuous': 2, '25': 2, 'if': 2, 'possible': 2, '37': 1, 'and': 6, 'cool': 1, '24': 3, '13': 3, 'friday': 6, '29': 2, 'with': 2, 'thunderstorms': 1, 'all': 1, 'outdoor': 3, 'activities': 3, 'saturday': 6, 'weekend': 3, 'postpone': 1, 'plans': 1, 'plan': 1, 'sunday': 6, 'direct': 1, 'sun': 1, 'exposure': 1, 'sunny': 1, 'occasional': 1, 'showers': 1, 'monsoon': 1, 'alert': 3, 'has': 2, 'crossed': 2, '200': 1, 'millimeters': 1, 'last': 1, 'low': 1, 'lying': 1, 'areas': 1, 'waterlogging': 1, 'many': 1, 'parts': 1, 'authorities': 1, 'have': 1, 'issued': 1, 'a': 1, 'schools': 1, 'remain': 1, 'closed': 1, 'heat': 2, 'wave': 2, '40': 1, 'going': 1, 'out': 1, 'between': 1, 'pm': 2, '3': 1}\n",
      "\n",
      "2-gram model:\n",
      "  Total contexts: 150\n",
      "  Sample contexts and their next tokens:\n",
      "    ('daily',) → {'weather': 1}\n",
      "    ('weather',) → {'reports': 1, 'report': 42, 'today': 21, '.': 5}\n",
      "    ('reports',) → {'for': 1}\n",
      "\n",
      "3-gram model:\n",
      "  Total contexts: 317\n",
      "  Sample contexts and their next tokens:\n",
      "    ('daily', 'weather') → {'reports': 1}\n",
      "    ('weather', 'reports') → {'for': 1}\n",
      "    ('reports', 'for') → {'major': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== N-gram Model Statistics ===\")\n",
    "\n",
    "for n in range(1, model.n_params + 1):\n",
    "    state = model.state[n-1]\n",
    "    print(f\"\\n{n}-gram model:\")\n",
    "    print(f\"  Total contexts: {len(state)}\")\n",
    "    \n",
    "    # Show some examples\n",
    "    if state:\n",
    "        print(\"  Sample contexts and their next tokens:\")\n",
    "        for i, (context, next_tokens) in enumerate(list(state.items())[:3]):\n",
    "            print(f\"    {context} → {dict(next_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5608bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_token(model, context):\n",
    "    \"\"\"Predict the most likely next token given context\"\"\"\n",
    "    for n in range(model.n_params, 1, -1):\n",
    "        if len(context) >= n - 1:\n",
    "            context_n = tuple(context[-(n - 1):])\n",
    "            counts = model.state[n - 1].get(context_n)\n",
    "            if counts:\n",
    "                return max(counts.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    # Fallback to unigram\n",
    "    unigram_counts = model.state[0].get(())\n",
    "    if unigram_counts:\n",
    "        return max(unigram_counts.items(), key=lambda x: x[1])[0]\n",
    "    return None\n",
    "\n",
    "def generate_text(model, context, num_tokens=10):\n",
    "    \"\"\"Generate text given a starting context\"\"\"\n",
    "    if isinstance(context, str):\n",
    "        context = model.tokenize(context)\n",
    "    \n",
    "    generated = list(context)\n",
    "    \n",
    "    for i in range(num_tokens):\n",
    "        next_token = predict_next_token(model, generated[-(model.n_params - 1):])\n",
    "        if next_token is None:\n",
    "            break\n",
    "        generated.append(next_token)\n",
    "    \n",
    "    return \" \".join(generated)\n",
    "\n",
    "print(\"Text generation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f955d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
